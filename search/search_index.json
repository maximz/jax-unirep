{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-\\.]+"},"docs":[{"location":"","text":"jax-unirep: A performant reimplementation of the UniRep model in JAX Welcome to the documentation of jax-unirep . jax-unirep is a reimplementation of the UniRep model, published by Biswas et. al. in 2020, implemented using JAX. Goals The goals of this project are to provide a performant reimplementation with a suite of user-friendly APIs to make usage of the UniRep model in protein machine learning applications more user-friendly.","title":"Home"},{"location":"#jax-unirep-a-performant-reimplementation-of-the-unirep-model-in-jax","text":"Welcome to the documentation of jax-unirep . jax-unirep is a reimplementation of the UniRep model, published by Biswas et. al. in 2020, implemented using JAX.","title":"jax-unirep: A performant reimplementation of the UniRep model in JAX"},{"location":"#goals","text":"The goals of this project are to provide a performant reimplementation with a suite of user-friendly APIs to make usage of the UniRep model in protein machine learning applications more user-friendly.","title":"Goals"},{"location":"advanced/","text":"Advanced Usage APIs that support \"advanced\" tasks are available in jax-unirep . Read on to learn how to use them. Evotuning In the original paper the concept of 'evolutionary finetuning' is introduced, where the pre-trained mLSTM weights get fine-tuned through weight-updates using homolog protein sequences of a given protein of interest as input. This feature is available as well in jax-unirep . Given a set of starter weights for the mLSTM (defaults to the weights from the paper) as well as a set of sequences, the weights get fine-tuned in such a way that test set loss in the 'next-aa prediction task' is minimized. There are two functions with differing levels of control available. The evotune function uses optuna under the hood to automatically find: the optimal number of epochs to train for, and the optimal learning rate, given a set of sequences. The study object will contain all the information about the training process of each trial. evotuned_params will contain the fine-tuned mLSTM and dense weights from the trial with the lowest test set loss. Speed freaks read this! As a heads-up, using evotune is kind of slow, so read on if you're of the impatient kind -- use fit ! If you want to directly fine-tune the weights for a fixed number of epochs while using a fixed learning rate, you should use the fit function instead. The fit function has further customization options, such as different batching strategies. Please see the function docstring here for more information. GPU usage The fit function will always default to using a GPU backend if available for the forward and backward passes during training of the LSTM. However, for the calulation of the average loss on the dataset after every epoch, you can decide if the CPU or GPU backend should be used (default is CPU). You can find an example usages of both evotune and fit here , but for convenience, here's a code block that you can copy/paste to get kickstarted. Read the docs! Can't emphasize this enough: Be sure to read the API docs for the fit function to learn about what's going on underneath the hood! from jax_unirep.utils import load_random_evotuning_params from random import shuffle from jax_unirep.evotuning import fit , dump_params # Prepare your sequences as a list of strings, # using whatever parsers you need. # This is a pre-requisite step that will likely be project-specific. seqs = [ ... ] # You can optionally split the dataset so that you have a holdout set. shuffle ( seqs ) break_point = int ( len ( seqs ) * 0.7 ) sequences = seqs [ 0 : break_point ] holdout_sequences = seqs [ break_point :] # Set some evotuning parameters. N_EPOCHS = 20 # probably want this to be quite high, like in the hundreds. LEARN_RATE = 1e-5 # this is a very sane default to start with. PROJECT_NAME = \"temp\" # where the weights will be dumped # Pre-load some evotuning params that are randomly initialized. params = load_random_evotuning_params () # Now to evotuning evotuned_params = fit ( params = params , # you can also set this to None if you want to use the published weights as the starting point. sequences = sequences , n_epochs = N_EPOCHS , step_size = LEARN_RATE , holdout_seqs = holdout_sequences , batch_method = \"random\" , proj_name = PROJECT_NAME , epochs_per_print = 1 , # also controls how often weights are dumped. backend = \"cpu\" , # default is \"cpu\", can also set to \"gpu\" if you have it. ) dump_params ( evotuned_params , PROJECT_NAME ) print ( \"Evotuning done! Find output weights in\" , PROJECT_NAME ) If you want to pass a set of mLSTM and dense weights that were dumped in an earlier run, create params as follows: from jax_unirep.utils import load_params params = load_params ( folderpath = \"path/to/params/folder\" ) If you want to start from randomly initialized mLSTM and dense weights instead: from jax_unirep.evotuning import init_fun from jax.random import PRNGKey _ , params = init_fun ( PRNGKey ( 0 ), input_shape = ( - 1 , 10 )) The weights used in the 10-dimensional embedding of the input sequences always default to the weights from the paper, since they do not get updated during evotuning. End-to-end differentiable models As a user, you might want to write custom \"top models\", such as a linear model on top of the reps, but might want to jointly optimize the UniRep weights with the top model reps. You're in luck! We implemented the mLSTM layers in such a way that they are compatible with jax.experimental.stax . This means that they can easily be plugged into a stax.serial model, e.g. to train both the mLSTM and a top-model at once: from jax.experimental import stax from jax.experimental.stax import Dense , Relu from jax_unirep.layers import mLSTM1900 , mLSTM1900_AvgHidden init_fun , apply_fun = stax . serial ( mLSTM1900 (), mLSTM1900_AvgHidden (), # Add two layers, one dense layer that results in 512-dim activations Dense ( 512 ), Relu (), # And then a linear layer to produce a 1-dim activation Dense ( 1 ) ) Have a look at the documentation and examples for more information about how to implement a model in jax . Sampling new protein sequences When doing protein engineering, one core task is proposing new sequences to order by gene synthesis. jax-unirep provides a number of utility functions inside jax_unirep.sampler that help with this task. Basic sampling The key one to focus on is the sample_one_chain function. This function takes in a starting sequence, and uses Monte Carlo sampling alongside the Metropolis-Hastings criteria to score and rank-order new sequences to try out. The usage pattern is as follows. Firstly, you must have a scoring function defined that takes in a string sequence, and outputs a number. This can be, for example, in the form of a pre-trained machine learning model that you have created. from jax_unirep import get_reps model = SomeSKLearnModel () model . fit ( training_X , training_y ) def scoring_func ( sequence : str ): reps , _ , _ = get_reps ( sequence ) return model . predict ( reps ) Now, we can use MCMC sampling to propose new sequences. from jax_unirep import sample_one_chain starter_seq = \"MKLNEQLJLA\" # can be longer! sampled_sequences = sample_one_chain ( starter_seq , n_steps = 10 , scoring_func = scoring_func ) sampled_seqs_df = pd . DataFrame ( sampled_sequences ) sampled_sequences is a dictionary that can be converted directly into a pandas.DataFrame . In there, every single sequence that was ever sampled is recorded, as well as its score (given by the scoring function) and whether it was accepted by the MCMC sampler or not. (All generated sequences are recorded, just in case there was something good that was rejected!) Parallel sampling If you want to do parallel sampling, you can use any library that does parallel processing. We're going to show you one example using Dask , which happens to be out favourite library for scalable Python! Assuming you have a Dask client object instantiated: client = Client ( ... ) # you'll have to configure this according to your own circumstances starter_seq = \"MKLNEQLJLA\" # can be longer! chain_results_futures = [] for i in range ( 100 ): # sample 100 independent chains chain_results_futures . append ( # Submit tasks to workers client . submit ( sample_one_chain , starter_seq , n_steps = 10 , scoring_func = scoring_func , pure = False # this is important, esp. with random sampling methods ) ) # Gather results from distributed workers chain_results = client . gather ( chain_results_futures ) # Convert everything into a single DataFrame chain_data = pd . concat ([ pd . DataFrame ( r ) for r in chain_results ]) Your contribution here Is there an \"advanced\" protocol that you've developed surrounding jax-unirep ? If so, please consider contributing it here!","title":"Advanced Usage"},{"location":"advanced/#advanced-usage","text":"APIs that support \"advanced\" tasks are available in jax-unirep . Read on to learn how to use them.","title":"Advanced Usage"},{"location":"advanced/#evotuning","text":"In the original paper the concept of 'evolutionary finetuning' is introduced, where the pre-trained mLSTM weights get fine-tuned through weight-updates using homolog protein sequences of a given protein of interest as input. This feature is available as well in jax-unirep . Given a set of starter weights for the mLSTM (defaults to the weights from the paper) as well as a set of sequences, the weights get fine-tuned in such a way that test set loss in the 'next-aa prediction task' is minimized. There are two functions with differing levels of control available. The evotune function uses optuna under the hood to automatically find: the optimal number of epochs to train for, and the optimal learning rate, given a set of sequences. The study object will contain all the information about the training process of each trial. evotuned_params will contain the fine-tuned mLSTM and dense weights from the trial with the lowest test set loss. Speed freaks read this! As a heads-up, using evotune is kind of slow, so read on if you're of the impatient kind -- use fit ! If you want to directly fine-tune the weights for a fixed number of epochs while using a fixed learning rate, you should use the fit function instead. The fit function has further customization options, such as different batching strategies. Please see the function docstring here for more information. GPU usage The fit function will always default to using a GPU backend if available for the forward and backward passes during training of the LSTM. However, for the calulation of the average loss on the dataset after every epoch, you can decide if the CPU or GPU backend should be used (default is CPU). You can find an example usages of both evotune and fit here , but for convenience, here's a code block that you can copy/paste to get kickstarted. Read the docs! Can't emphasize this enough: Be sure to read the API docs for the fit function to learn about what's going on underneath the hood! from jax_unirep.utils import load_random_evotuning_params from random import shuffle from jax_unirep.evotuning import fit , dump_params # Prepare your sequences as a list of strings, # using whatever parsers you need. # This is a pre-requisite step that will likely be project-specific. seqs = [ ... ] # You can optionally split the dataset so that you have a holdout set. shuffle ( seqs ) break_point = int ( len ( seqs ) * 0.7 ) sequences = seqs [ 0 : break_point ] holdout_sequences = seqs [ break_point :] # Set some evotuning parameters. N_EPOCHS = 20 # probably want this to be quite high, like in the hundreds. LEARN_RATE = 1e-5 # this is a very sane default to start with. PROJECT_NAME = \"temp\" # where the weights will be dumped # Pre-load some evotuning params that are randomly initialized. params = load_random_evotuning_params () # Now to evotuning evotuned_params = fit ( params = params , # you can also set this to None if you want to use the published weights as the starting point. sequences = sequences , n_epochs = N_EPOCHS , step_size = LEARN_RATE , holdout_seqs = holdout_sequences , batch_method = \"random\" , proj_name = PROJECT_NAME , epochs_per_print = 1 , # also controls how often weights are dumped. backend = \"cpu\" , # default is \"cpu\", can also set to \"gpu\" if you have it. ) dump_params ( evotuned_params , PROJECT_NAME ) print ( \"Evotuning done! Find output weights in\" , PROJECT_NAME ) If you want to pass a set of mLSTM and dense weights that were dumped in an earlier run, create params as follows: from jax_unirep.utils import load_params params = load_params ( folderpath = \"path/to/params/folder\" ) If you want to start from randomly initialized mLSTM and dense weights instead: from jax_unirep.evotuning import init_fun from jax.random import PRNGKey _ , params = init_fun ( PRNGKey ( 0 ), input_shape = ( - 1 , 10 )) The weights used in the 10-dimensional embedding of the input sequences always default to the weights from the paper, since they do not get updated during evotuning.","title":"Evotuning"},{"location":"advanced/#end-to-end-differentiable-models","text":"As a user, you might want to write custom \"top models\", such as a linear model on top of the reps, but might want to jointly optimize the UniRep weights with the top model reps. You're in luck! We implemented the mLSTM layers in such a way that they are compatible with jax.experimental.stax . This means that they can easily be plugged into a stax.serial model, e.g. to train both the mLSTM and a top-model at once: from jax.experimental import stax from jax.experimental.stax import Dense , Relu from jax_unirep.layers import mLSTM1900 , mLSTM1900_AvgHidden init_fun , apply_fun = stax . serial ( mLSTM1900 (), mLSTM1900_AvgHidden (), # Add two layers, one dense layer that results in 512-dim activations Dense ( 512 ), Relu (), # And then a linear layer to produce a 1-dim activation Dense ( 1 ) ) Have a look at the documentation and examples for more information about how to implement a model in jax .","title":"End-to-end differentiable models"},{"location":"advanced/#sampling-new-protein-sequences","text":"When doing protein engineering, one core task is proposing new sequences to order by gene synthesis. jax-unirep provides a number of utility functions inside jax_unirep.sampler that help with this task.","title":"Sampling new protein sequences"},{"location":"advanced/#basic-sampling","text":"The key one to focus on is the sample_one_chain function. This function takes in a starting sequence, and uses Monte Carlo sampling alongside the Metropolis-Hastings criteria to score and rank-order new sequences to try out. The usage pattern is as follows. Firstly, you must have a scoring function defined that takes in a string sequence, and outputs a number. This can be, for example, in the form of a pre-trained machine learning model that you have created. from jax_unirep import get_reps model = SomeSKLearnModel () model . fit ( training_X , training_y ) def scoring_func ( sequence : str ): reps , _ , _ = get_reps ( sequence ) return model . predict ( reps ) Now, we can use MCMC sampling to propose new sequences. from jax_unirep import sample_one_chain starter_seq = \"MKLNEQLJLA\" # can be longer! sampled_sequences = sample_one_chain ( starter_seq , n_steps = 10 , scoring_func = scoring_func ) sampled_seqs_df = pd . DataFrame ( sampled_sequences ) sampled_sequences is a dictionary that can be converted directly into a pandas.DataFrame . In there, every single sequence that was ever sampled is recorded, as well as its score (given by the scoring function) and whether it was accepted by the MCMC sampler or not. (All generated sequences are recorded, just in case there was something good that was rejected!)","title":"Basic sampling"},{"location":"advanced/#parallel-sampling","text":"If you want to do parallel sampling, you can use any library that does parallel processing. We're going to show you one example using Dask , which happens to be out favourite library for scalable Python! Assuming you have a Dask client object instantiated: client = Client ( ... ) # you'll have to configure this according to your own circumstances starter_seq = \"MKLNEQLJLA\" # can be longer! chain_results_futures = [] for i in range ( 100 ): # sample 100 independent chains chain_results_futures . append ( # Submit tasks to workers client . submit ( sample_one_chain , starter_seq , n_steps = 10 , scoring_func = scoring_func , pure = False # this is important, esp. with random sampling methods ) ) # Gather results from distributed workers chain_results = client . gather ( chain_results_futures ) # Convert everything into a single DataFrame chain_data = pd . concat ([ pd . DataFrame ( r ) for r in chain_results ])","title":"Parallel sampling"},{"location":"advanced/#your-contribution-here","text":"Is there an \"advanced\" protocol that you've developed surrounding jax-unirep ? If so, please consider contributing it here!","title":"Your contribution here"},{"location":"api/","text":"API Documentation Here lies the official top-level API for interacting with jax-unirep . Calculating Representations jax_unirep.get_reps jax_unirep. get_reps ( seqs , params=None ) Get reps of proteins. This function generates representations of protein sequences using the 1900 hidden-unit mLSTM model with pre-trained weights from the UniRep paper . Each element of the output 3-tuple is a np.array of shape (n_input_sequences, 1900): h_avg : Average hidden state of the mLSTM over the whole sequence. h_final : Final hidden state of the mLSTM c_final : Final cell state of the mLSTM You should not use this function if you want to do further JAX-based computations on the output vectors! In that case, the DeviceArray futures returned by mLSTM1900 should be passed directly into the next step instead of converting them to np.array s. The conversion to np.array s is done in the dispatched rep_x_lengths functions to force python to wait with returning the values until the computation is completed. The keys of the params dictionary must be: b, gh, gmh, gmx, gx, wh, wmh, wmx, wx Parameters seqs : A list of sequences as strings or a single string. params : A dictionary of mLSTM1900 weights. Returns A 3-tuple of np.array s containing the reps, in the order h_avg , h_final , and c_final . Each np.array has shape (n_sequences, 1900). Evotuning jax_unirep.fit jax_unirep. fit ( params , sequences , n_epochs , batch_method='random' , batch_size=25 , step_size=0.0001 , holdout_seqs=None , proj_name='temp' , epochs_per_print=1 , backend='cpu' ) Return mLSTM weights fitted to predict the next letter in each AA sequence. The training loop is as follows, depending on the batching strategy: Length batching: At each iteration, of all sequence lengths present in sequences , one length gets chosen at random. Next, batch_size number of sequences of the chosen length get selected at random. If there are less sequences of a given length than batch_size , all sequences of that length get chosen. Those sequences then get passed through the model. No padding of sequences occurs. To get batching of sequences by length done, we call on batch_sequences from our utils.py module, which returns a list of sub-lists, in which each sub-list contains the indices in the original list of sequences that are of a particular length. Random batching: Before training, all sequences get padded to be the same length as the longest sequence in sequences . Then, at each iteration, we randomly sample batch_size sequences and pass them through the model. The training loop does not adhere to the common notion of epochs , where all sequences would be seen by the model exactly once per epoch. Instead sequences always get sampled at random, and one epoch approximately consists of round(len(sequences) / batch_size) weight updates. Asymptotically, this should be approximately equivalent to doing epoch passes over the dataset. To learn more about the passing of params , have a look at the evotune function docstring. You can optionally dump parameters and print weights every epochs_per_print epochs to monitor training progress. For ergonomics, training/holdout set losses are estimated on a batch size the same as batch_size , rather than calculated exactly on the entire set. Set epochs_per_print to None to avoid parameter dumping. Parameters params : mLSTM1900 and Dense parameters. sequences : List of sequences to evotune on. n : The number of iterations to evotune on. batch_method : One of \"length\" or \"random\". batch_size : If random batching is used, number of sequences per batch. As a rule of thumb, batch size of 50 consumes about 5GB of GPU RAM. step_size : The learning rate. holdout_seqs : Holdout set, an optional input. proj_name : The directory path for weights to be output to. epochs_per_print : Number of epochs to progress before printing and dumping of weights. Must be greater than or equal to 1. backend : Whether or not to use the GPU. Defaults to \"cpu\", but can be set to \"gpu\" if desired. Returns Final optimized parameters. jax_unirep.evotune jax_unirep. evotune ( sequences , params=None , proj_name='temp' , out_dom_seqs=None , n_trials=20 , n_epochs_config=None , learning_rate_config=None , n_splits=5 , epochs_per_print=200 ) Evolutionarily tune the model to a set of sequences. Evotuning is described in the original UniRep and eUniRep papers. This reimplementation of evotune provides a nicer API that automatically handles multiple sequences of variable lengths. Evotuning always needs a starter set of weights. By default, the pre-trained weights from the Nature Methods paper are used. However, other pre-trained weights are legitimate. We first use optuna to figure out how many epochs to fit before overfitting happens. To save on computation time, the number of trials run defaults to 20, but can be configured. By default, mLSTM1900 and Dense weights from the paper are used by passing in params=None , but if you want to use randomly intialized weights: from jax_unirep.evotuning import init_fun from jax.random import PRNGKey _ , params = init_fun ( PRNGKey ( 0 ), input_shape = ( - 1 , 10 )) or dumped weights: from jax_unirep.utils import load_params params = load_params ( folderpath = \"path/to/params/folder\" ) This function is intended as an automagic way of identifying the best model and training routine hyperparameters. If you want more control over how fitting happens, please use the fit() function directly. There is an example in the examples/ directory that shows how to use it. Parameters sequences : Sequences to evotune against. params : Parameters to be passed into mLSTM1900 and Dense . Optional; if None, will default to weights from paper, or you can pass in your own set of parameters, as long as they are stax-compatible. proj_name : Name of the project, used to name created output directory. out_dom_seqs : Out-domain holdout set of sequences, to check for loss on to prevent overfitting. `n_trials: The number of trials Optuna should attempt. n_epochs_config : A dictionary of kwargs to trial.suggest_discrete_uniform , which are: name , low , high , q . This controls how many epochs to have Optuna test. See source code for default configuration, at the definition of n_epochs_kwargs . learning_rate_config : A dictionary of kwargs to trial.suggest_loguniform , which are: name , low , high . This controls the learning rate of the model. See source code for default configuration, at the definition of learning_rate_kwargs . n_splits : The number of folds of cross-validation to do. epochs_per_print : The number of steps between each printing and dumping of weights in the final evotuning step using the optimized hyperparameters. Returns study : The optuna study object, containing information about all evotuning trials. evotuned_params : A dictionary of the final, optimized weights. Sampling jax_unirep.sample_one_chain jax_unirep. sample_one_chain ( starter_sequence , n_steps , scoring_func , is_accepted_kwargs={} , trust_radius=7 , propose_kwargs={} ) Return one chain of MCMC samples of new sequences. Given a starter_sequence , this function will sample one chain of protein sequences, scored using a user-provided scoring_func . Design choices made here include the following. Firstly, we record all sequences that were sampled, and not just the accepted ones. This behaviour differs from other MCMC samplers that record only the accepted values. We do this just in case sequences that are still \"good\" (but not better than current) are rejected. The effect here is that we get a cluster of sequences that are one-apart from newly accepted sequences. Secondly, we check the Hamming distance between the newly proposed sequences and the original. This corresponds to the \"trust radius\" specified in the jax-unirep paper . If the hamming distance > trust radius, we reject the sequence outright. A dictionary containing the following key-value pairs are returned: \"sequences\": All proposed sequences. \"scores\": All scores from the scoring function. \"accept\": Whether the sequence was accepted as the new 'current sequence' on which new sequences are proposed. This can be turned into a pandas DataFrame. Parameters starter_sequence : The starting sequence. n_steps : Number of steps for the MC chain to walk. scoring_func : Scoring function for a new sequence. It should only accept a string sequence . is_accepted_kwargs : Dictionary of kwargs to pass into is_accepted function. See is_accepted docstring for more details. trust_radius : Maximum allowed number of mutations away from starter sequence. propose_kwargs : Dictionary of kwargs to pass into propose function. See propose docstring for more details. verbose : Whether or not to print iteration number and associated sequence + score. Defaults to False Returns A dictionary with sequences , accept and score as keys.","title":"API Docs"},{"location":"api/#api-documentation","text":"Here lies the official top-level API for interacting with jax-unirep .","title":"API Documentation"},{"location":"api/#calculating-representations","text":"","title":"Calculating Representations"},{"location":"api/#jax_unirepget_reps","text":"jax_unirep. get_reps ( seqs , params=None ) Get reps of proteins. This function generates representations of protein sequences using the 1900 hidden-unit mLSTM model with pre-trained weights from the UniRep paper . Each element of the output 3-tuple is a np.array of shape (n_input_sequences, 1900): h_avg : Average hidden state of the mLSTM over the whole sequence. h_final : Final hidden state of the mLSTM c_final : Final cell state of the mLSTM You should not use this function if you want to do further JAX-based computations on the output vectors! In that case, the DeviceArray futures returned by mLSTM1900 should be passed directly into the next step instead of converting them to np.array s. The conversion to np.array s is done in the dispatched rep_x_lengths functions to force python to wait with returning the values until the computation is completed. The keys of the params dictionary must be: b, gh, gmh, gmx, gx, wh, wmh, wmx, wx","title":"jax_unirep.get_reps"},{"location":"api/#evotuning","text":"","title":"Evotuning"},{"location":"api/#jax_unirepfit","text":"jax_unirep. fit ( params , sequences , n_epochs , batch_method='random' , batch_size=25 , step_size=0.0001 , holdout_seqs=None , proj_name='temp' , epochs_per_print=1 , backend='cpu' ) Return mLSTM weights fitted to predict the next letter in each AA sequence. The training loop is as follows, depending on the batching strategy: Length batching: At each iteration, of all sequence lengths present in sequences , one length gets chosen at random. Next, batch_size number of sequences of the chosen length get selected at random. If there are less sequences of a given length than batch_size , all sequences of that length get chosen. Those sequences then get passed through the model. No padding of sequences occurs. To get batching of sequences by length done, we call on batch_sequences from our utils.py module, which returns a list of sub-lists, in which each sub-list contains the indices in the original list of sequences that are of a particular length. Random batching: Before training, all sequences get padded to be the same length as the longest sequence in sequences . Then, at each iteration, we randomly sample batch_size sequences and pass them through the model. The training loop does not adhere to the common notion of epochs , where all sequences would be seen by the model exactly once per epoch. Instead sequences always get sampled at random, and one epoch approximately consists of round(len(sequences) / batch_size) weight updates. Asymptotically, this should be approximately equivalent to doing epoch passes over the dataset. To learn more about the passing of params , have a look at the evotune function docstring. You can optionally dump parameters and print weights every epochs_per_print epochs to monitor training progress. For ergonomics, training/holdout set losses are estimated on a batch size the same as batch_size , rather than calculated exactly on the entire set. Set epochs_per_print to None to avoid parameter dumping.","title":"jax_unirep.fit"},{"location":"api/#jax_unirepevotune","text":"jax_unirep. evotune ( sequences , params=None , proj_name='temp' , out_dom_seqs=None , n_trials=20 , n_epochs_config=None , learning_rate_config=None , n_splits=5 , epochs_per_print=200 ) Evolutionarily tune the model to a set of sequences. Evotuning is described in the original UniRep and eUniRep papers. This reimplementation of evotune provides a nicer API that automatically handles multiple sequences of variable lengths. Evotuning always needs a starter set of weights. By default, the pre-trained weights from the Nature Methods paper are used. However, other pre-trained weights are legitimate. We first use optuna to figure out how many epochs to fit before overfitting happens. To save on computation time, the number of trials run defaults to 20, but can be configured. By default, mLSTM1900 and Dense weights from the paper are used by passing in params=None , but if you want to use randomly intialized weights: from jax_unirep.evotuning import init_fun from jax.random import PRNGKey _ , params = init_fun ( PRNGKey ( 0 ), input_shape = ( - 1 , 10 )) or dumped weights: from jax_unirep.utils import load_params params = load_params ( folderpath = \"path/to/params/folder\" ) This function is intended as an automagic way of identifying the best model and training routine hyperparameters. If you want more control over how fitting happens, please use the fit() function directly. There is an example in the examples/ directory that shows how to use it.","title":"jax_unirep.evotune"},{"location":"api/#sampling","text":"","title":"Sampling"},{"location":"api/#jax_unirepsample_one_chain","text":"jax_unirep. sample_one_chain ( starter_sequence , n_steps , scoring_func , is_accepted_kwargs={} , trust_radius=7 , propose_kwargs={} ) Return one chain of MCMC samples of new sequences. Given a starter_sequence , this function will sample one chain of protein sequences, scored using a user-provided scoring_func . Design choices made here include the following. Firstly, we record all sequences that were sampled, and not just the accepted ones. This behaviour differs from other MCMC samplers that record only the accepted values. We do this just in case sequences that are still \"good\" (but not better than current) are rejected. The effect here is that we get a cluster of sequences that are one-apart from newly accepted sequences. Secondly, we check the Hamming distance between the newly proposed sequences and the original. This corresponds to the \"trust radius\" specified in the jax-unirep paper . If the hamming distance > trust radius, we reject the sequence outright. A dictionary containing the following key-value pairs are returned: \"sequences\": All proposed sequences. \"scores\": All scores from the scoring function. \"accept\": Whether the sequence was accepted as the new 'current sequence' on which new sequences are proposed. This can be turned into a pandas DataFrame.","title":"jax_unirep.sample_one_chain"},{"location":"contributing/","text":"Contributing This page will show you how to get involved with contributing to the development of jax-unirep . Bug Reports Bug reports are definitely welcome on the issue tracker ! In filing a bug report, please produce a reproducible example. The standard for a reproducible example is that anyone with jax-unirep installed can copy/paste the code with no modifications into a Jupyter notebook (or other interpreter) and execute the code with no modifications. Doing this helps a ton with debugging and reduces maintainer friction in trying to help with debugging. If we are able to hit the root of the problem, we might post a possible solution and encourage you to submit a pull request so that you can partake in open source software co-creation with us. It's fun, and we're really sure you'd like it too ;). Documentation As maintainers of the package, we're inevitably going to have blind spots. If you find one, and think others would benefit from that blind spot being eliminated in the docs, please submit a pull request! All docs are housed in the docs/ directory, and are plain Markdown files, which should make editing easy, whether on GitHub or locally. Feature Requests Feature requests are always welcome to be posted on the issue tracker ! That said, please temper your expectations, as jax-unirep development happens as and when the lead maintainers (Arkadij Kummer and Eric Ma) encounter needs in their day jobs. We welcome your pull requests, and are happy to guide you through the development process and work with you to get what you need into the library, but any requests for us to implement features will be prioritized according to what we encounter in our day jobs. If you make in a pull request that gets accepted, we are more than happy to publicly acknowledge your contributions and by sending tons of positive vibes throughout the Twitterverse and our LinkedIn connections!","title":"Contributing"},{"location":"contributing/#contributing","text":"This page will show you how to get involved with contributing to the development of jax-unirep .","title":"Contributing"},{"location":"contributing/#bug-reports","text":"Bug reports are definitely welcome on the issue tracker ! In filing a bug report, please produce a reproducible example. The standard for a reproducible example is that anyone with jax-unirep installed can copy/paste the code with no modifications into a Jupyter notebook (or other interpreter) and execute the code with no modifications. Doing this helps a ton with debugging and reduces maintainer friction in trying to help with debugging. If we are able to hit the root of the problem, we might post a possible solution and encourage you to submit a pull request so that you can partake in open source software co-creation with us. It's fun, and we're really sure you'd like it too ;).","title":"Bug Reports"},{"location":"contributing/#documentation","text":"As maintainers of the package, we're inevitably going to have blind spots. If you find one, and think others would benefit from that blind spot being eliminated in the docs, please submit a pull request! All docs are housed in the docs/ directory, and are plain Markdown files, which should make editing easy, whether on GitHub or locally.","title":"Documentation"},{"location":"contributing/#feature-requests","text":"Feature requests are always welcome to be posted on the issue tracker ! That said, please temper your expectations, as jax-unirep development happens as and when the lead maintainers (Arkadij Kummer and Eric Ma) encounter needs in their day jobs. We welcome your pull requests, and are happy to guide you through the development process and work with you to get what you need into the library, but any requests for us to implement features will be prioritized according to what we encounter in our day jobs. If you make in a pull request that gets accepted, we are more than happy to publicly acknowledge your contributions and by sending tons of positive vibes throughout the Twitterverse and our LinkedIn connections!","title":"Feature Requests"},{"location":"development/","text":"Development This page will show you the officially-supported ways of getting set up with a development environment so that you can hack on jax-unirep and make contributions! Get familiar with community practices Kevin Markham has a great resource on how to contribute to open source software on GitHub. We'd really encourage you to look through it first if you're not already familiar with canonical, community workflow practices that have been adopted across multiple open source projects. The most basic ideas that you'll need to grasp are: Making forks. Local vs. remote. VSCode Dev Containers The easiest way for you to get setup is to use a dev container with VSCode. (We're not paid by Microsoft, we're just fans of this way of working.) To get started: Fork the repository. Ensure you have Docker running on your local machine. Ensure you have VSCode running on your local machine. In Visual Studio Code, click on the quick actions Status Bar item in the lower left corner. Then select \u201cRemote Containers: Open Repository In Container\u201d. Enter in the URL of your fork of pyjanitor. VSCode will pull down the prebuilt Docker container, git clone the repository for you inside an isolated Docker volume, and mount the repository directory inside your Docker container. Follow best practices to submit a pull request by making a feature branch. Now, hack away, and submit in your pull request! You shouln\u2019t be able to access the cloned repo on your local hard drive. If you do want local access, then clone the repo locally first before selecting \u201cRemote Containers: Open Folder In Container\u201d. If you find something is broken because a utility is missing in the container, submit a PR with the appropriate build command inserted in the Dockerfile. Care has been taken to document what each step does, so please read the in-line documentation in the Dockerfile carefully. Conda Environment This is another supported way of working. We assume that you already have the Anaconda distribution of Python setup on your local machine. Once you've done that: Fork the repository. Clone your fork locally. In your terminal, enter into the local copy of the repository. Now, install the environment: conda env create -f environment.yml This will create an environment called jax-unirep that you can activate. conda activate jax-unirep Finally, install jax-unirep into your environment in development mode. python setup.py develop Your favourite way here If you've got well-documented steps for how to get setup, come contribute them as part of the docs here! You'll want to edit docs/development.md . Then submit a pull request in: everyone in the community will benefit!","title":"Development"},{"location":"development/#development","text":"This page will show you the officially-supported ways of getting set up with a development environment so that you can hack on jax-unirep and make contributions!","title":"Development"},{"location":"development/#get-familiar-with-community-practices","text":"Kevin Markham has a great resource on how to contribute to open source software on GitHub. We'd really encourage you to look through it first if you're not already familiar with canonical, community workflow practices that have been adopted across multiple open source projects. The most basic ideas that you'll need to grasp are: Making forks. Local vs. remote.","title":"Get familiar with community practices"},{"location":"development/#vscode-dev-containers","text":"The easiest way for you to get setup is to use a dev container with VSCode. (We're not paid by Microsoft, we're just fans of this way of working.) To get started: Fork the repository. Ensure you have Docker running on your local machine. Ensure you have VSCode running on your local machine. In Visual Studio Code, click on the quick actions Status Bar item in the lower left corner. Then select \u201cRemote Containers: Open Repository In Container\u201d. Enter in the URL of your fork of pyjanitor. VSCode will pull down the prebuilt Docker container, git clone the repository for you inside an isolated Docker volume, and mount the repository directory inside your Docker container. Follow best practices to submit a pull request by making a feature branch. Now, hack away, and submit in your pull request! You shouln\u2019t be able to access the cloned repo on your local hard drive. If you do want local access, then clone the repo locally first before selecting \u201cRemote Containers: Open Folder In Container\u201d. If you find something is broken because a utility is missing in the container, submit a PR with the appropriate build command inserted in the Dockerfile. Care has been taken to document what each step does, so please read the in-line documentation in the Dockerfile carefully.","title":"VSCode Dev Containers"},{"location":"development/#conda-environment","text":"This is another supported way of working. We assume that you already have the Anaconda distribution of Python setup on your local machine. Once you've done that: Fork the repository. Clone your fork locally. In your terminal, enter into the local copy of the repository. Now, install the environment: conda env create -f environment.yml This will create an environment called jax-unirep that you can activate. conda activate jax-unirep Finally, install jax-unirep into your environment in development mode. python setup.py develop","title":"Conda Environment"},{"location":"development/#your-favourite-way-here","text":"If you've got well-documented steps for how to get setup, come contribute them as part of the docs here! You'll want to edit docs/development.md . Then submit a pull request in: everyone in the community will benefit!","title":"Your favourite way here"},{"location":"getting-started/","text":"Getting Started Installation Ensure that your compute environment allows you to run JAX code. (A modern Linux or macOS with a GLIBC>=2.23 is probably necessary.) Then, install from PyPI: pip install jax-unirep On the roadmap is support for installation from PyPI and conda-forge. Basic Usage The core activity with using UniRep is to produce fixed-length representations of protein sequences. This is done by using the get_reps() function. You can \"rep\" a single sequence: from jax_unirep import get_reps sequence = \"ASDFGHJKL\" # h_avg is the canonical \"reps\" h_avg , h_final , c_final = get_reps ( sequence ) Or you can \"rep\" a bunch of sequences together: from jax_unirep import get_reps sequences = [ \"ASDF\" , \"YJKAL\" , \"QQLAMEHALQP\" ] # h_avg is the canonical \"reps\" h_avg , h_final , c_final = get_reps ( sequences ) # each of the arrays will be of shape (len(sequences), 1900), # with the correct order of sequences preserved Canonically, you would use h_avg as the \"reps\".","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#installation","text":"Ensure that your compute environment allows you to run JAX code. (A modern Linux or macOS with a GLIBC>=2.23 is probably necessary.) Then, install from PyPI: pip install jax-unirep On the roadmap is support for installation from PyPI and conda-forge.","title":"Installation"},{"location":"getting-started/#basic-usage","text":"The core activity with using UniRep is to produce fixed-length representations of protein sequences. This is done by using the get_reps() function. You can \"rep\" a single sequence: from jax_unirep import get_reps sequence = \"ASDFGHJKL\" # h_avg is the canonical \"reps\" h_avg , h_final , c_final = get_reps ( sequence ) Or you can \"rep\" a bunch of sequences together: from jax_unirep import get_reps sequences = [ \"ASDF\" , \"YJKAL\" , \"QQLAMEHALQP\" ] # h_avg is the canonical \"reps\" h_avg , h_final , c_final = get_reps ( sequences ) # each of the arrays will be of shape (len(sequences), 1900), # with the correct order of sequences preserved Canonically, you would use h_avg as the \"reps\".","title":"Basic Usage"},{"location":"improvements/","text":"Improvements What have we done with jax-unirep that improve upon the original ? Primarily, we have made improvements in three areas. Firstly, speed through reimplementation: By leveraging modern automatic differentiation packages, specifically JAX, we were able to accelerate the UniRep model over 100X over the original. Our preprint on bioarxiv provides additional detail on our claim. Secondly, robustness: we have extensively unit tested the model code, so that others may use it with confidence. The code has 96% test coverage, and we leverage Travis CI for continuous integration, such that every change is tested extensively. Thirdly, user-friendly APIs: Most of our expected user base should be not-so-technical protein engineers. (\"Technical\" being extensively comfortable with Python; protein engineering is a very technical discipline!) As such, developed APIs that prevent many sources of user error that may interfere with safe handling of UniRep. One example is that our most commonly-used functions, for calculating representations of proteins and evotuning, always accept Python strings rather than hand-prepared tensors. Finally, docs: The fact that you're here means you're benefiting from the hosted API docs! We hope you find it to be easy to use and navigate.","title":"Improvements"},{"location":"improvements/#improvements","text":"What have we done with jax-unirep that improve upon the original ? Primarily, we have made improvements in three areas. Firstly, speed through reimplementation: By leveraging modern automatic differentiation packages, specifically JAX, we were able to accelerate the UniRep model over 100X over the original. Our preprint on bioarxiv provides additional detail on our claim. Secondly, robustness: we have extensively unit tested the model code, so that others may use it with confidence. The code has 96% test coverage, and we leverage Travis CI for continuous integration, such that every change is tested extensively. Thirdly, user-friendly APIs: Most of our expected user base should be not-so-technical protein engineers. (\"Technical\" being extensively comfortable with Python; protein engineering is a very technical discipline!) As such, developed APIs that prevent many sources of user error that may interfere with safe handling of UniRep. One example is that our most commonly-used functions, for calculating representations of proteins and evotuning, always accept Python strings rather than hand-prepared tensors. Finally, docs: The fact that you're here means you're benefiting from the hosted API docs! We hope you find it to be easy to use and navigate.","title":"Improvements"},{"location":"paper/","text":"Introduction UniRep is a recurrent neural network, trained using self-supervision on 24 million protein sequences to predict the next amino acid in a sequence [@alley2019unified]. Its most powerful model allows for embedding arbitrary length sequences in a 1900-long feature vector that can be used as the input to a \"top model\" for unsupervised clustering or supervised prediction of protein properties. The original model was implemented in TensorFlow 1.13 [@abadi2016tensorflow], and its original API only allowed for one sequence to be transformed at once. While test-driving the model, we observed two problems with it. The first is that that the original implementation took an abnormally long amount of time to process multiple sequences, requiring on the order of dozens of seconds to process single sequences. The second was that its API was not sufficiently flexible to handle multiple sequences passed in at once; to get reps of multiple sequences, one needed to write a manual for-loop, re-using a function inside which returns the reps for a single sequence. When fine-tuning model weights, sequences needed to be batched and padded to equal lengths before being able to be passed in to the model. Neither appeared to be user-friendly. Thus, while the model itself holds great potential for the protein engineering field, the API prevents us from using it conveniently and productively. We thus sought to reimplement and package the model in a way that brings a robust yet easy-to-use experience to protein modellers and engineers. In particular, our engineering goals were to provide: A function that can process multiple sequences of arbitrary lengths, Vectorizing the inputs to make it fast. A single function call to \"evotune\" the global weights. Profiling tf-unirep and jax-unirep To investigate the performance of the original and our reimplementation, we used Python's cProfile facility to identify where the majority of time was spent in the respective codebases. The functions used for profiling were: # assume babbler is imported from tf-unirep def profile_tf_unirep ( seqs ): with tf . variable_scope ( \"embed_matrix\" , reuse = tf . AUTO_REUSE ): b = babbler ( batch_size = batch_size , model_path = MODEL_WEIGHT_PATH ) for seq in seqs : avg , final , cell = b . get_rep ( seq ) # assume get_reps is imported from jax-unirep def profile_jax_unirep ( seqs ): get_reps ( seqs ) We then used SnakeViz to visualize the code execution profile results. As is visible from the code execution flamegraph, the unreasonably long time that it takes to process ten sequences was probably due to the time spent in TensorFlow's session. Because of TensorFlow's compiled nature, we thus deduced that the majority of the execution time was most likely in the graph compilation phase. Unfortunately, cProfile could not give us any further detail beyond the _pywrap_tensorflow_internal.TF_SessionRun_wrapper in the call graph, meaning we were unable to conveniently peer into the internals of TF execution without digging further. On the basis of this profiling, we hypothesized that the cause of speed problems was graph compilation in TF1.x, and that we could obtain speedups by using a non-graph-compiled tensor library. There were three choices for us at this point: TF2.x, PyTorch and JAX, and we chose the latter. Our choice was motivated by the following reasons: JAX uses the NumPy API, which is idiomatic in the Python scientific computing community. JAX provides automatic differentiation, which would enable us to reimplement weights fine-tuning. JAX encourages functional programming, which makes implementation of neural network layers different from class-based implementations (e.g. PyTorch and Keras). This was an intellectual curiosity point for us. JAX is \"eagerly\" executable like PyTorch and TF2, which aids debugging. Besides these a priori motivating reasons, we also uncovered other reasons to use JAX midway: JAX's compiled and automatically differentiable primitives (e.g. lax.scan ) allowed us to write performant RNN code. jit and vmap helped with writing performant training loops. We thus reimplemented the model in JAX/NumPy. (See \"Reimplementation Main Points\" section for details.) As is visible from the code profiling APIs that we used, we designed a cleaner and more expressive API that could be faster and handle multiple sequences of variable lengths, without introducing the mental overhead of TensorFlow's complex scoping syntax. An expressive and clean API was something that we would expect a computational protein engineer would desire, as having this API form would lower mental overhead while also hopefully being faster to execute and write. A formal speed comparison using the same CPU is available below. {width=50%} We also needed to check that our reimplementation correctly embeds sequences. To do so, we ran a dummy sequence through the original and through our reimplementation, and compared the computed representations. Because it is 1900-long, a visual check for correctness is a trace of 1900-long embedding. We also verified that the embeddings calculated using the pre-trained weights were informative for top models, and trained a model to predict the brightness of around 50'000 avGFP variants (as the authors did). avGFP is a green-fluorescent protein that has been extensively studied in the literature. Many studies generated mutants of this protein, measuring the changes in brightness for each mutant, to try to understand how protein sequence links to function or simply to increase brightness. We binarized brightness values into a \"dark\" and a \"bright\" class, and used scikit-learn's implementation of logistic regression for classification. Average performance across 5-fold cross-validation is shown in Figure 3. (avGFP data came from [@sarkisyan2016local].) Reimplementation Main Points Choice of JAX JAX was our library choice to reimplement it in, because it provides automatic differentiation machinery [@jax2018github] on top of the highly idiomatic and widely-used NumPy API [@oliphant2006guide]. JAX uses a number of components shared with TensorFlow, in particular the use of the XLA (Accelerated Linear Algebra) library to provide automatic compilation from the NumPy API to GPU and TPU. Part of the exercise was also pedagogical: by reimplementing the model in a pure NumPy API, we are forced to become familiar with the mechanics of the model, and learn the translation between NumPy and TensorFlow operations. This helps us be flexible in moving between frameworks. Because JAX provides automatic differentiation and a number of optimization routines as utility functions, we are thus not prohibited from fine-tuning UniRep weights through gradient descent. During the reimplementation, we also discovered that JAX provided convenient utilities ( lax.scan , vmap , and jit ) to convert loops into fast, vectorized operations on tensors. This had a pleasant effect of helping us write more performant code. We were also forced to reason clearly about the semantic meaning of our tensor dimensions, to make sure that vecotrization happened over the correct axes. We commented at every tensor operation step how the shapes of our input(s) and output(s) should look like. One example from our source: # layers.py # Shape annotation # (:, 10) @ (10, 1900) * (:, 1900) @ (1900, 1900) => (:, 1900) m = np . matmul ( x_t , params [ \"wmx\" ]) * np . matmul ( h_t , params [ \"wmh\" ]) # (:, 10) @ (10, 7600) * (:, 1900) @ (1900, 7600) + (7600, ) => (:, 7600) z = np . matmul ( x_t , params [ \"wx\" ]) + np . matmul ( m , params [ \"wh\" ]) + params [ \"b\" ] # ... Tensor Ops Reimplementation The process of tensor ops reimplementation were as follows. Firstly, we started from the RNN cell ( mLSTM1900_step ), which sequentially walks down the protein sequence and generates the single step embedding. We thus end up with a \"unit cell\" function: def mlstm1900_step ( params , carry , x_t ): h_t , c_t = carry # Unit cell implementation goes here. return ( h_t , c_t ), h_t Secondly, we wrapped the RNN cell using lax.scan to scan over a single sequence. This is the mlstm1900_batch function: def mlstm1900_batch ( params , batch ): # code setup goes here. step_func = partial ( mlstm1900_step , params ) # use of lax.scan below: ( h_final , c_final ), outputs = lax . scan ( step_func , init = ( h_t , c_t ), xs = batch ) return h_final , c_final , outputs Thirdly, we then used jax.vmap to vectorize the operation over multiple sequences, thus generating mlstm1900 : def mlstm1900 ( params , x ): def mlstm1900_vmappable ( x ): return mlstm1900_batch ( params = params , batch = x ) h_final , c_final , outputs = vmap ( mlstm1900_vmappable )( x ) return h_final , c_final , outputs Effectively, jax.vmap and lax.scan replace for-loops that we would otherwise write, which would incur Python type-checking overhead that would accumulate. lax.scan being effectively a pre-compiled for-loop enables pre-allocation of the necessary memory needed for backpropagation, which also contributes to a speed-up. As the for-loop type checking penalty is well-known in Python, a detailed comparison between jax.vmap , lax.scan , and a vanilla for loop is out of scope for this paper. The full source code is available in jax_unirep/layers.py . Besides reimplementation, we also took care to document the semantic meaning of tensor dimensions. This had the pleasant side effect of forcing us to order our tensor dimensions in a sane fashion, such that the \"batch\" or \"sample\" dimension was always the first one, with explicit documentation written to guide a new user on this convention. While reimplementing the model, we also generated a test suite for it. Most of our tests check that the shapes of returned tensors were correct. For the unit RNN cell, we provided an example-based test with random matrices. The same applied to the batch function. However, for the full forward model, we provided a property-based test, which checked that tensor dimensions were correct given different numbers of samples. These are available in the source tests/ directory. As a known benefit with software testing, our tests allowed us to rebuild the full model piece by piece, while always making sure that each new piece did not break the existing pieces. Utility Reimplementation For the get_reps() functionality, we copied quite a bit of source code from the original, including the original authors' implementation of embedding a sequence into an l l -by-10 embedding matrix first. However, we added tests to guarantee that they were robust, as well as technical documentation to clarify how it works. We did this because one way that deep learning models can be fragile is that the input tensors can be generated incorrectly but still have the expected shapes. Thus, though the structure of input tensors might be correct, their semantic meaning would be completely wrong. (Adversarial examples can be generated this way.) Thus, the input to the model has to be carefully controlled. Moreover, input tensors are not the raw-est form of data; for a protein engineer, the protein sequence is. Thus, having robustly tested functions that generate the input tensors with correct semantic meaning is crucial to having confidence that the model works correctly end-to-end. APIs Because we expect the model to be used as a Python library, the model source and weights are packaged together. This makes it much more convenient for end-users, as the cognitive load of downloading starter weights is eliminated. The get_reps() function is designed such that it is flexible enough to accept a single sequence or an iterable of sequences. This also reduces cognitive load for end-users, some of whom might want to process only a single sequence, while others might be operating in batch mode. get_reps() also correctly handles sequences of multiple lengths, further simplifying usage for end-users. In particular, we spent time ensuring that get_reps() correctly batches sequences of the same size together before calculating their reps, while returning the reps in the same order as the sequences passed in. As usual, tests are provided, bringing the same degree of confidence as we would expect from tested software. Lessons Learned We found the reimplementation exercise to be highly educational. In particular, we gained a mechanical understanding of the model, and through documenting the model functions thoroughly with the semantic meaning of tensor dimensions, we were able to greatly reduce our own confusion when debugging why the model would fail. During the reimplementation, we found the \"sigmoid\" function to be an overloaded term. We initially used a sigmoid that had an incorrect slope, yielding incorrect reps. Switching to the correct sigmoid slope rectified the problem. A similar lesson was learned while reimplementing the L2 norm of our weights. Writing automated tests for the model functions, in basically the same way as we would test software, gave us the confidence that our code changes would not inadvertently break existing functionality that was also already tested. We also could then more easily narrow down where failures were happening when developing new code that interacted with the model (such as providing input tensors). Through reimplementation, we took the opportunity to document the semantic meaning of tensor axes and their order, thus enabling ourselves to better understand the model's semantic structure, while also enabling others to more easily participate in the model's improvement and development. Competing tensor libraries that do not interoperate seamlessly means data scientists are forced to learn one (and be mentally locked in). To break free of framework lock-in, being able to translate between frameworks is highly valuable. Model reimplementation was highly beneficial for this. UniRep was implemented in Tensorflow 1.13. It is well-known that TF1's computation graph-oriented API does not promote ease of debugging in native Python. Hence, it may sometimes be difficult to find spots in a TF model where one could speed up computations. By instead treating neural network layers as functions that are eagerly evaluated, we could more easily debug model problems, in particular, the pernicious tensor shape issues. We believe that the speedup that we observed by reimplementing in JAX came primarily from eliminating graph compilation overhead and an enhanced version of the original API design. In anecdotal tests, graph compilation would take on the order of seconds before any computation occurred. Because the original implementation's get_reps function did not accept multiple sequences, one had to use a for-loop to pass sequence strings through the model. If a user were not careful, in a worst-case scenario, they would end up essentially paying the compilation penalty on every loop iteration. By preprocessing strings in batches of the same size, and by keeping track of the original ordering, then we could (1) avoid compilation penalty, and (2) vectorize much of the tensor operations over the sample axis, before returning the representation vectors in the original order of the sequences. In ensuring that the enhanced get_reps API accepted multiple sequences, we also reduced cognitive load for a Python-speaking protein data scientist who might be seeking to use the model, as the function safely handles a single string and an iterable of strings. An overarching lesson we derive from this experience is as follows. If \"models are software 2.0\" [@kaparthy2017software2], then data science teams might do well to treat fitted model weights as software artefacts that are shipped to end-users, and take care to design sane APIs that enable other developers to use it in ways that minimize cognitive load. Future Work As we have, at this point, only implemented the 1900-cell model. Going forth, we aim to work on implementing the 256- and 64-cell model. Evotuning is an important task when using UniRep [@alley2019unified], and we aim to provide a convenient API through the evotune() function. Here, we plan to use Optuna to automatically find the right hyperparameters for finetuning weights, using the protocol that the original authors describe. This would enable end-users to \"set and forget\" the model fitting protocol rather than needing to babysit a deep learning optimization routine. Like get_reps() , evotune() and its associated utility functions will have at least an example-based test, if not also a property-based test associated with them. Community contributions and enhancements are welcome as well. Software Repository jax-unirep is available on GitHub at https://github.com/ElArkk/jax-unirep. Acknowledgments We thank the UniRep authors for open sourcing their model. It is our hope that our reimplementation helps with adoption of the model in a variety of settings, and increases its impact. References","title":"Reimplementing Unirep in JAX"},{"location":"paper/#introduction","text":"UniRep is a recurrent neural network, trained using self-supervision on 24 million protein sequences to predict the next amino acid in a sequence [@alley2019unified]. Its most powerful model allows for embedding arbitrary length sequences in a 1900-long feature vector that can be used as the input to a \"top model\" for unsupervised clustering or supervised prediction of protein properties. The original model was implemented in TensorFlow 1.13 [@abadi2016tensorflow], and its original API only allowed for one sequence to be transformed at once. While test-driving the model, we observed two problems with it. The first is that that the original implementation took an abnormally long amount of time to process multiple sequences, requiring on the order of dozens of seconds to process single sequences. The second was that its API was not sufficiently flexible to handle multiple sequences passed in at once; to get reps of multiple sequences, one needed to write a manual for-loop, re-using a function inside which returns the reps for a single sequence. When fine-tuning model weights, sequences needed to be batched and padded to equal lengths before being able to be passed in to the model. Neither appeared to be user-friendly. Thus, while the model itself holds great potential for the protein engineering field, the API prevents us from using it conveniently and productively. We thus sought to reimplement and package the model in a way that brings a robust yet easy-to-use experience to protein modellers and engineers. In particular, our engineering goals were to provide: A function that can process multiple sequences of arbitrary lengths, Vectorizing the inputs to make it fast. A single function call to \"evotune\" the global weights.","title":"Introduction"},{"location":"paper/#profiling-tf-unirep-and-jax-unirep","text":"To investigate the performance of the original and our reimplementation, we used Python's cProfile facility to identify where the majority of time was spent in the respective codebases. The functions used for profiling were: # assume babbler is imported from tf-unirep def profile_tf_unirep ( seqs ): with tf . variable_scope ( \"embed_matrix\" , reuse = tf . AUTO_REUSE ): b = babbler ( batch_size = batch_size , model_path = MODEL_WEIGHT_PATH ) for seq in seqs : avg , final , cell = b . get_rep ( seq ) # assume get_reps is imported from jax-unirep def profile_jax_unirep ( seqs ): get_reps ( seqs ) We then used SnakeViz to visualize the code execution profile results. As is visible from the code execution flamegraph, the unreasonably long time that it takes to process ten sequences was probably due to the time spent in TensorFlow's session. Because of TensorFlow's compiled nature, we thus deduced that the majority of the execution time was most likely in the graph compilation phase. Unfortunately, cProfile could not give us any further detail beyond the _pywrap_tensorflow_internal.TF_SessionRun_wrapper in the call graph, meaning we were unable to conveniently peer into the internals of TF execution without digging further. On the basis of this profiling, we hypothesized that the cause of speed problems was graph compilation in TF1.x, and that we could obtain speedups by using a non-graph-compiled tensor library. There were three choices for us at this point: TF2.x, PyTorch and JAX, and we chose the latter. Our choice was motivated by the following reasons: JAX uses the NumPy API, which is idiomatic in the Python scientific computing community. JAX provides automatic differentiation, which would enable us to reimplement weights fine-tuning. JAX encourages functional programming, which makes implementation of neural network layers different from class-based implementations (e.g. PyTorch and Keras). This was an intellectual curiosity point for us. JAX is \"eagerly\" executable like PyTorch and TF2, which aids debugging. Besides these a priori motivating reasons, we also uncovered other reasons to use JAX midway: JAX's compiled and automatically differentiable primitives (e.g. lax.scan ) allowed us to write performant RNN code. jit and vmap helped with writing performant training loops. We thus reimplemented the model in JAX/NumPy. (See \"Reimplementation Main Points\" section for details.) As is visible from the code profiling APIs that we used, we designed a cleaner and more expressive API that could be faster and handle multiple sequences of variable lengths, without introducing the mental overhead of TensorFlow's complex scoping syntax. An expressive and clean API was something that we would expect a computational protein engineer would desire, as having this API form would lower mental overhead while also hopefully being faster to execute and write. A formal speed comparison using the same CPU is available below. {width=50%} We also needed to check that our reimplementation correctly embeds sequences. To do so, we ran a dummy sequence through the original and through our reimplementation, and compared the computed representations. Because it is 1900-long, a visual check for correctness is a trace of 1900-long embedding. We also verified that the embeddings calculated using the pre-trained weights were informative for top models, and trained a model to predict the brightness of around 50'000 avGFP variants (as the authors did). avGFP is a green-fluorescent protein that has been extensively studied in the literature. Many studies generated mutants of this protein, measuring the changes in brightness for each mutant, to try to understand how protein sequence links to function or simply to increase brightness. We binarized brightness values into a \"dark\" and a \"bright\" class, and used scikit-learn's implementation of logistic regression for classification. Average performance across 5-fold cross-validation is shown in Figure 3. (avGFP data came from [@sarkisyan2016local].)","title":"Profiling tf-unirep and jax-unirep"},{"location":"paper/#reimplementation-main-points","text":"","title":"Reimplementation Main Points"},{"location":"paper/#choice-of-jax","text":"JAX was our library choice to reimplement it in, because it provides automatic differentiation machinery [@jax2018github] on top of the highly idiomatic and widely-used NumPy API [@oliphant2006guide]. JAX uses a number of components shared with TensorFlow, in particular the use of the XLA (Accelerated Linear Algebra) library to provide automatic compilation from the NumPy API to GPU and TPU. Part of the exercise was also pedagogical: by reimplementing the model in a pure NumPy API, we are forced to become familiar with the mechanics of the model, and learn the translation between NumPy and TensorFlow operations. This helps us be flexible in moving between frameworks. Because JAX provides automatic differentiation and a number of optimization routines as utility functions, we are thus not prohibited from fine-tuning UniRep weights through gradient descent. During the reimplementation, we also discovered that JAX provided convenient utilities ( lax.scan , vmap , and jit ) to convert loops into fast, vectorized operations on tensors. This had a pleasant effect of helping us write more performant code. We were also forced to reason clearly about the semantic meaning of our tensor dimensions, to make sure that vecotrization happened over the correct axes. We commented at every tensor operation step how the shapes of our input(s) and output(s) should look like. One example from our source: # layers.py # Shape annotation # (:, 10) @ (10, 1900) * (:, 1900) @ (1900, 1900) => (:, 1900) m = np . matmul ( x_t , params [ \"wmx\" ]) * np . matmul ( h_t , params [ \"wmh\" ]) # (:, 10) @ (10, 7600) * (:, 1900) @ (1900, 7600) + (7600, ) => (:, 7600) z = np . matmul ( x_t , params [ \"wx\" ]) + np . matmul ( m , params [ \"wh\" ]) + params [ \"b\" ] # ...","title":"Choice of JAX"},{"location":"paper/#tensor-ops-reimplementation","text":"The process of tensor ops reimplementation were as follows. Firstly, we started from the RNN cell ( mLSTM1900_step ), which sequentially walks down the protein sequence and generates the single step embedding. We thus end up with a \"unit cell\" function: def mlstm1900_step ( params , carry , x_t ): h_t , c_t = carry # Unit cell implementation goes here. return ( h_t , c_t ), h_t Secondly, we wrapped the RNN cell using lax.scan to scan over a single sequence. This is the mlstm1900_batch function: def mlstm1900_batch ( params , batch ): # code setup goes here. step_func = partial ( mlstm1900_step , params ) # use of lax.scan below: ( h_final , c_final ), outputs = lax . scan ( step_func , init = ( h_t , c_t ), xs = batch ) return h_final , c_final , outputs Thirdly, we then used jax.vmap to vectorize the operation over multiple sequences, thus generating mlstm1900 : def mlstm1900 ( params , x ): def mlstm1900_vmappable ( x ): return mlstm1900_batch ( params = params , batch = x ) h_final , c_final , outputs = vmap ( mlstm1900_vmappable )( x ) return h_final , c_final , outputs Effectively, jax.vmap and lax.scan replace for-loops that we would otherwise write, which would incur Python type-checking overhead that would accumulate. lax.scan being effectively a pre-compiled for-loop enables pre-allocation of the necessary memory needed for backpropagation, which also contributes to a speed-up. As the for-loop type checking penalty is well-known in Python, a detailed comparison between jax.vmap , lax.scan , and a vanilla for loop is out of scope for this paper. The full source code is available in jax_unirep/layers.py . Besides reimplementation, we also took care to document the semantic meaning of tensor dimensions. This had the pleasant side effect of forcing us to order our tensor dimensions in a sane fashion, such that the \"batch\" or \"sample\" dimension was always the first one, with explicit documentation written to guide a new user on this convention. While reimplementing the model, we also generated a test suite for it. Most of our tests check that the shapes of returned tensors were correct. For the unit RNN cell, we provided an example-based test with random matrices. The same applied to the batch function. However, for the full forward model, we provided a property-based test, which checked that tensor dimensions were correct given different numbers of samples. These are available in the source tests/ directory. As a known benefit with software testing, our tests allowed us to rebuild the full model piece by piece, while always making sure that each new piece did not break the existing pieces.","title":"Tensor Ops Reimplementation"},{"location":"paper/#utility-reimplementation","text":"For the get_reps() functionality, we copied quite a bit of source code from the original, including the original authors' implementation of embedding a sequence into an l l -by-10 embedding matrix first. However, we added tests to guarantee that they were robust, as well as technical documentation to clarify how it works. We did this because one way that deep learning models can be fragile is that the input tensors can be generated incorrectly but still have the expected shapes. Thus, though the structure of input tensors might be correct, their semantic meaning would be completely wrong. (Adversarial examples can be generated this way.) Thus, the input to the model has to be carefully controlled. Moreover, input tensors are not the raw-est form of data; for a protein engineer, the protein sequence is. Thus, having robustly tested functions that generate the input tensors with correct semantic meaning is crucial to having confidence that the model works correctly end-to-end.","title":"Utility Reimplementation"},{"location":"paper/#apis","text":"Because we expect the model to be used as a Python library, the model source and weights are packaged together. This makes it much more convenient for end-users, as the cognitive load of downloading starter weights is eliminated. The get_reps() function is designed such that it is flexible enough to accept a single sequence or an iterable of sequences. This also reduces cognitive load for end-users, some of whom might want to process only a single sequence, while others might be operating in batch mode. get_reps() also correctly handles sequences of multiple lengths, further simplifying usage for end-users. In particular, we spent time ensuring that get_reps() correctly batches sequences of the same size together before calculating their reps, while returning the reps in the same order as the sequences passed in. As usual, tests are provided, bringing the same degree of confidence as we would expect from tested software.","title":"APIs"},{"location":"paper/#lessons-learned","text":"We found the reimplementation exercise to be highly educational. In particular, we gained a mechanical understanding of the model, and through documenting the model functions thoroughly with the semantic meaning of tensor dimensions, we were able to greatly reduce our own confusion when debugging why the model would fail. During the reimplementation, we found the \"sigmoid\" function to be an overloaded term. We initially used a sigmoid that had an incorrect slope, yielding incorrect reps. Switching to the correct sigmoid slope rectified the problem. A similar lesson was learned while reimplementing the L2 norm of our weights. Writing automated tests for the model functions, in basically the same way as we would test software, gave us the confidence that our code changes would not inadvertently break existing functionality that was also already tested. We also could then more easily narrow down where failures were happening when developing new code that interacted with the model (such as providing input tensors). Through reimplementation, we took the opportunity to document the semantic meaning of tensor axes and their order, thus enabling ourselves to better understand the model's semantic structure, while also enabling others to more easily participate in the model's improvement and development. Competing tensor libraries that do not interoperate seamlessly means data scientists are forced to learn one (and be mentally locked in). To break free of framework lock-in, being able to translate between frameworks is highly valuable. Model reimplementation was highly beneficial for this. UniRep was implemented in Tensorflow 1.13. It is well-known that TF1's computation graph-oriented API does not promote ease of debugging in native Python. Hence, it may sometimes be difficult to find spots in a TF model where one could speed up computations. By instead treating neural network layers as functions that are eagerly evaluated, we could more easily debug model problems, in particular, the pernicious tensor shape issues. We believe that the speedup that we observed by reimplementing in JAX came primarily from eliminating graph compilation overhead and an enhanced version of the original API design. In anecdotal tests, graph compilation would take on the order of seconds before any computation occurred. Because the original implementation's get_reps function did not accept multiple sequences, one had to use a for-loop to pass sequence strings through the model. If a user were not careful, in a worst-case scenario, they would end up essentially paying the compilation penalty on every loop iteration. By preprocessing strings in batches of the same size, and by keeping track of the original ordering, then we could (1) avoid compilation penalty, and (2) vectorize much of the tensor operations over the sample axis, before returning the representation vectors in the original order of the sequences. In ensuring that the enhanced get_reps API accepted multiple sequences, we also reduced cognitive load for a Python-speaking protein data scientist who might be seeking to use the model, as the function safely handles a single string and an iterable of strings. An overarching lesson we derive from this experience is as follows. If \"models are software 2.0\" [@kaparthy2017software2], then data science teams might do well to treat fitted model weights as software artefacts that are shipped to end-users, and take care to design sane APIs that enable other developers to use it in ways that minimize cognitive load.","title":"Lessons Learned"},{"location":"paper/#future-work","text":"As we have, at this point, only implemented the 1900-cell model. Going forth, we aim to work on implementing the 256- and 64-cell model. Evotuning is an important task when using UniRep [@alley2019unified], and we aim to provide a convenient API through the evotune() function. Here, we plan to use Optuna to automatically find the right hyperparameters for finetuning weights, using the protocol that the original authors describe. This would enable end-users to \"set and forget\" the model fitting protocol rather than needing to babysit a deep learning optimization routine. Like get_reps() , evotune() and its associated utility functions will have at least an example-based test, if not also a property-based test associated with them. Community contributions and enhancements are welcome as well.","title":"Future Work"},{"location":"paper/#software-repository","text":"jax-unirep is available on GitHub at https://github.com/ElArkk/jax-unirep.","title":"Software Repository"},{"location":"paper/#acknowledgments","text":"We thank the UniRep authors for open sourcing their model. It is our hope that our reimplementation helps with adoption of the model in a variety of settings, and increases its impact.","title":"Acknowledgments"},{"location":"paper/#references","text":"","title":"References"},{"location":"suppinf/","text":"Supplementary information - Jax-unirep Speed profiling of Unirep The functions used for profiling the original UniRep implementation and our jax-unirep reimplementation respectively: # assume babbler is imported from tf-unirep def profile_tf_unirep ( seqs ): with tf . variable_scope ( \"embed_matrix\" , reuse = tf . AUTO_REUSE ): b = babbler ( batch_size = batch_size , model_path = MODEL_WEIGHT_PATH ) for seq in seqs : avg , final , cell = b . get_rep ( seq ) # assume get_reps is imported from jax-unirep def profile_jax_unirep ( seqs ): get_reps ( seqs ) As is visible from the code execution flamegraph, the unreasonably long time that it takes to process ten sequences was probably due to the time spent in TensorFlow's session. Because of TensorFlow's compiled nature, we thus deduced that the majority of the execution time was most likely in the graph compilation phase. Unfortunately, cProfile could not give us any further detail beyond the _pywrap_tensorflow_internal.TF_SessionRun_wrapper in the call graph, meaning we were unable to conveniently peer into the internals of TF execution without digging further. Reimplementation Main Points Tensor Ops Reimplementation The process of tensor ops reimplementation were as follows. Firstly, we started from the RNN cell ( mLSTM1900_step ), which sequentially walks down the protein sequence and generates the single step embedding. We thus end up with a \"unit cell\" function: def mlstm1900_step ( params , carry , x_t ): h_t , c_t = carry # Unit cell implementation goes here. return ( h_t , c_t ), h_t Secondly, we wrapped the RNN cell using lax.scan to scan over a single sequence. This is the mlstm1900_batch function: def mlstm1900_batch ( params , batch ): # code setup goes here. step_func = partial ( mlstm1900_step , params ) # use of lax.scan below: ( h_final , c_final ), outputs = lax . scan ( step_func , init = ( h_t , c_t ), xs = batch ) return h_final , c_final , outputs Thirdly, we then used jax.vmap to vectorize the operation over multiple sequences, thus generating mlstm1900 : def mlstm1900 ( params , x ): def mlstm1900_vmappable ( x ): return mlstm1900_batch ( params = params , batch = x ) h_final , c_final , outputs = vmap ( mlstm1900_vmappable )( x ) return h_final , c_final , outputs Effectively, jax.vmap and lax.scan replace for-loops that we would otherwise write, which would incur Python type-checking overhead that would accumulate. lax.scan being effectively a pre-compiled for-loop enables pre-allocation of the necessary memory needed for backpropagation, which also contributes to a speed-up. As the for-loop type checking penalty is well-known in Python, a detailed comparison between jax.vmap , lax.scan , and a vanilla for loop is out of scope for this paper. The full source code is available in jax_unirep/layers.py . Besides reimplementation, we also took care to document the semantic meaning of tensor dimensions. This had the pleasant side effect of forcing us to order our tensor dimensions in a sane fashion, such that the \"batch\" or \"sample\" dimension was always the first one, with explicit documentation written to guide a new user on this convention. While reimplementing the model, we also generated a test suite for it. Most of our tests check that the shapes of returned tensors were correct. For the unit RNN cell, we provided an example-based test with random matrices. The same applied to the batch function. However, for the full forward model, we provided a property-based test, which checked that tensor dimensions were correct given different numbers of samples. These are available in the source tests/ directory. As a known benefit with software testing, our tests allowed us to rebuild the full model piece by piece, while always making sure that each new piece did not break the existing pieces. Utility Reimplementation For the get_reps() functionality, we copied quite a bit of source code from the original, including the original authors' implementation of embedding a sequence into an l l -by-10 embedding matrix first. However, we added tests to guarantee that they were robust, as well as technical documentation to clarify how it works. We did this because one way that deep learning models can be fragile is that the input tensors can be generated incorrectly but still have the expected shapes. Thus, though the structure of input tensors might be correct, their semantic meaning would be completely wrong. (Adversarial examples can be generated this way.) Thus, the input to the model has to be carefully controlled. Moreover, input tensors are not the raw-est form of data; for a protein engineer, the protein sequence is. Thus, having robustly tested functions that generate the input tensors with correct semantic meaning is crucial to having confidence that the model works correctly end-to-end. APIs Because we expect the model to be used as a Python library, the model source and weights are packaged together. This makes it much more convenient for end-users, as the cognitive load of downloading starter weights is eliminated. The get_reps() function is designed such that it is flexible enough to accept a single sequence or an iterable of sequences. This also reduces cognitive load for end-users, some of whom might want to process only a single sequence, while others might be operating in batch mode. get_reps() also correctly handles sequences of multiple lengths, further simplifying usage for end-users. In particular, we spent time ensuring that get_reps() correctly batches sequences of the same size together before calculating their reps, while returning the reps in the same order as the sequences passed in. As usual, tests are provided, bringing the same degree of confidence as we would expect from tested software. Top model To test our reimplementation in a practical workflow, we recreated the GFP brightness prediction model that was introduced in the original paper. We trained the model on the same set of GFP mutants as the orignial authors did, but used the get_reps function to embed the protein sequences that we then passed to the classification model. The model performance shown below is based on 5-fold crossvalidation of the whole GFP dataset. The full analysis is available as a jupyter notebook in the jax-unirep repository.","title":"Supplementary information - Jax-unirep"},{"location":"suppinf/#supplementary-information-jax-unirep","text":"","title":"Supplementary information - Jax-unirep"},{"location":"suppinf/#speed-profiling-of-unirep","text":"The functions used for profiling the original UniRep implementation and our jax-unirep reimplementation respectively: # assume babbler is imported from tf-unirep def profile_tf_unirep ( seqs ): with tf . variable_scope ( \"embed_matrix\" , reuse = tf . AUTO_REUSE ): b = babbler ( batch_size = batch_size , model_path = MODEL_WEIGHT_PATH ) for seq in seqs : avg , final , cell = b . get_rep ( seq ) # assume get_reps is imported from jax-unirep def profile_jax_unirep ( seqs ): get_reps ( seqs ) As is visible from the code execution flamegraph, the unreasonably long time that it takes to process ten sequences was probably due to the time spent in TensorFlow's session. Because of TensorFlow's compiled nature, we thus deduced that the majority of the execution time was most likely in the graph compilation phase. Unfortunately, cProfile could not give us any further detail beyond the _pywrap_tensorflow_internal.TF_SessionRun_wrapper in the call graph, meaning we were unable to conveniently peer into the internals of TF execution without digging further.","title":"Speed profiling of Unirep"},{"location":"suppinf/#reimplementation-main-points","text":"","title":"Reimplementation Main Points"},{"location":"suppinf/#tensor-ops-reimplementation","text":"The process of tensor ops reimplementation were as follows. Firstly, we started from the RNN cell ( mLSTM1900_step ), which sequentially walks down the protein sequence and generates the single step embedding. We thus end up with a \"unit cell\" function: def mlstm1900_step ( params , carry , x_t ): h_t , c_t = carry # Unit cell implementation goes here. return ( h_t , c_t ), h_t Secondly, we wrapped the RNN cell using lax.scan to scan over a single sequence. This is the mlstm1900_batch function: def mlstm1900_batch ( params , batch ): # code setup goes here. step_func = partial ( mlstm1900_step , params ) # use of lax.scan below: ( h_final , c_final ), outputs = lax . scan ( step_func , init = ( h_t , c_t ), xs = batch ) return h_final , c_final , outputs Thirdly, we then used jax.vmap to vectorize the operation over multiple sequences, thus generating mlstm1900 : def mlstm1900 ( params , x ): def mlstm1900_vmappable ( x ): return mlstm1900_batch ( params = params , batch = x ) h_final , c_final , outputs = vmap ( mlstm1900_vmappable )( x ) return h_final , c_final , outputs Effectively, jax.vmap and lax.scan replace for-loops that we would otherwise write, which would incur Python type-checking overhead that would accumulate. lax.scan being effectively a pre-compiled for-loop enables pre-allocation of the necessary memory needed for backpropagation, which also contributes to a speed-up. As the for-loop type checking penalty is well-known in Python, a detailed comparison between jax.vmap , lax.scan , and a vanilla for loop is out of scope for this paper. The full source code is available in jax_unirep/layers.py . Besides reimplementation, we also took care to document the semantic meaning of tensor dimensions. This had the pleasant side effect of forcing us to order our tensor dimensions in a sane fashion, such that the \"batch\" or \"sample\" dimension was always the first one, with explicit documentation written to guide a new user on this convention. While reimplementing the model, we also generated a test suite for it. Most of our tests check that the shapes of returned tensors were correct. For the unit RNN cell, we provided an example-based test with random matrices. The same applied to the batch function. However, for the full forward model, we provided a property-based test, which checked that tensor dimensions were correct given different numbers of samples. These are available in the source tests/ directory. As a known benefit with software testing, our tests allowed us to rebuild the full model piece by piece, while always making sure that each new piece did not break the existing pieces.","title":"Tensor Ops Reimplementation"},{"location":"suppinf/#utility-reimplementation","text":"For the get_reps() functionality, we copied quite a bit of source code from the original, including the original authors' implementation of embedding a sequence into an l l -by-10 embedding matrix first. However, we added tests to guarantee that they were robust, as well as technical documentation to clarify how it works. We did this because one way that deep learning models can be fragile is that the input tensors can be generated incorrectly but still have the expected shapes. Thus, though the structure of input tensors might be correct, their semantic meaning would be completely wrong. (Adversarial examples can be generated this way.) Thus, the input to the model has to be carefully controlled. Moreover, input tensors are not the raw-est form of data; for a protein engineer, the protein sequence is. Thus, having robustly tested functions that generate the input tensors with correct semantic meaning is crucial to having confidence that the model works correctly end-to-end.","title":"Utility Reimplementation"},{"location":"suppinf/#apis","text":"Because we expect the model to be used as a Python library, the model source and weights are packaged together. This makes it much more convenient for end-users, as the cognitive load of downloading starter weights is eliminated. The get_reps() function is designed such that it is flexible enough to accept a single sequence or an iterable of sequences. This also reduces cognitive load for end-users, some of whom might want to process only a single sequence, while others might be operating in batch mode. get_reps() also correctly handles sequences of multiple lengths, further simplifying usage for end-users. In particular, we spent time ensuring that get_reps() correctly batches sequences of the same size together before calculating their reps, while returning the reps in the same order as the sequences passed in. As usual, tests are provided, bringing the same degree of confidence as we would expect from tested software.","title":"APIs"},{"location":"suppinf/#top-model","text":"To test our reimplementation in a practical workflow, we recreated the GFP brightness prediction model that was introduced in the original paper. We trained the model on the same set of GFP mutants as the orignial authors did, but used the get_reps function to embed the protein sequences that we then passed to the classification model. The model performance shown below is based on 5-fold crossvalidation of the whole GFP dataset. The full analysis is available as a jupyter notebook in the jax-unirep repository.","title":"Top model"}]}